<?xml version='1.0' encoding='utf-8'?>
<rss xmlns:itunes="http://www.itunes.com/dtds/podcast-1.0.dtd" version="2.0"><channel><title>AI Foundations and Implementation Feed</title><link>https://surly-16.github.io/js-audio-feed/AI%20Foundations%20and%20Implementation/</link><description>Narrated episodes on AI Foundations and Implementation</description><language>en-au</language><itunes:explicit>no</itunes:explicit><itunes:image href="https://github.com/surly-16/js-audio-feed/blob/main/AI%20Foundations%20and%20Implementation/cover.png?raw=true" /><image><url>https://github.com/surly-16/js-audio-feed/blob/main/AI%20Foundations%20and%20Implementation/cover.png?raw=true</url><title>AI Foundations and Implementation Feed</title><link>https://surly-16.github.io/js-audio-feed/AI%20Foundations%20and%20Implementation/</link></image><item><title>006 Ai Opportunity Mapping Using Process Improvement</title><guid>006_ai_opportunity_mapping_using_process_improvement</guid><pubDate>Sun, 15 Jun 2025 03:13:09 +1000</pubDate><enclosure url="https://github.com/surly-16/js-audio-feed/raw/refs/heads/main/AI%20Foundations%20and%20Implementation/media/006_ai_opportunity_mapping_using_process_improvement.mp3" length="5191725" type="audio/mpeg" /><description>Narrated episode: 006 Ai Opportunity Mapping Using Process Improvement

Right now, across every major bank in Australia, there's a fundamental shift happening in how we approach process improvement. We're moving from asking "how can we automate this task?" to "how can we fundamentally reimagine this process with AI?" And the teams getting this right aren't the ones with the biggest budgets or the most data scientists—they're the ones who understand how to map AI capabilities to specific process pain points.



Let me share what we're seeing. Last quarter, one of our risk teams reduced their model validation cycle from three weeks to four days. Not through some revolutionary new algorithm, but by applying classic process improvement thinking to their AI implementation. They mapped their existing workflow, identified the constraint—manual data reconciliation—and deployed a targeted LLM solution that could read unstructured validation reports and flag discrepancies.



This is the opportunity mapping framework we've developed, and it's transforming how we approach AI initiatives across the bank. Instead of starting with the technology and looking for problems to solve, we're starting with process performance metrics and working backwards to the right AI solution.



Think about your current process improvement toolkit. You've got value stream mapping, root cause analysis, statistical process control. Now imagine augmenting each of these with AI capabilities. Value stream mapping becomes intelligent process mining that automatically identifies bottlenecks from system logs. Root cause analysis gets supercharged with machine learning models that can detect patterns humans miss. Statistical process control evolves into predictive analytics that flag issues before they impact customers.




Here's the framework we use. First, we categorize processes by their AI readiness score. This isn't about technical complexity—it's about business impact and regulatory constraints. A high-readiness process has clear success metrics, structured data inputs, and sits outside critical regulatory reporting chains. Think customer service ticket routing or marketing campaign optimization.




Medium-readiness processes have some unstructured elements or touch regulated activities indirectly. These are your credit assessment support tools or compliance monitoring dashboards. Low-readiness processes directly impact regulatory reporting or require explainable decision-making. Your core credit decisioning or AML transaction monitoring systems.



The mistake most teams make is starting with low-readiness processes because that's where the biggest pain points are. But under CPS 230, any AI system touching critical operations needs extensive documentation, validation, and ongoing monitoring. Start with high-readiness processes to build your MLOps capabilities and stakeholder confidence.



Let me walk you through a real example. Our home loan processing team identified document verification as their biggest bottleneck. Traditional approach would be to throw OCR and rules-based extraction at it. But when we mapped the process end-to-end, we discovered the real constraint wasn't reading the documents—it was the decision logic around exception handling.



So we built a two-stage solution. First, a computer vision model that could classify documents and extract key fields with confidence scores. Second, an LLM-based reasoning engine that could handle exceptions by referencing our lending policies. The key innovation? We didn't try to automate the entire process. We automated the 80% of standard cases and built an elegant handoff to human experts for the complex ones.



This hybrid approach is critical in banking. ASIC Report 798 makes it clear—you need to maintain human oversight for significant decisions. But that doesn't mean AI can't dramatically improve the process. Our loan processors now focus on genuinely complex cases while AI handles the routine verification. Processing time dropped 60%, but more importantly, error rates fell by 40% because humans weren't fatigued by repetitive tasks.




Now, let's talk about the technical architecture that makes this possible. You can't just deploy models in isolation—you need an integrated ecosystem. We've built what we call the AI Process Platform. It combines process mining tools like Celonis or ProcessGold with our ML platform, whether that's SageMaker, Vertex AI, or Azure ML. The process mining continuously monitors performance and feeds that data back to retrain our models.




This creates a virtuous cycle. The AI improves the process, the process generates better data, which improves the AI. But here's where your Six Sigma background becomes invaluable. You need to establish control limits and monitoring before you deploy. What's your baseline performance? What variance is acceptable? When should the system escalate to human review?



We use a traffic light system for AI confidence. Green light—full automation, the model is highly confident and operating within expected parameters. Amber light—automation with human review, the model has flagged something unusual. Red light—full human processing, the input is outside the model's training distribution or touches a high-risk scenario.



This approach satisfies regulatory requirements while maximizing efficiency. CPS 230 requires us to demonstrate ongoing model performance monitoring. By building these controls into the process design, compliance becomes automatic rather than an afterthought.



Let's shift to implementation strategy. The biggest challenge isn't technical—it's organizational. You're asking teams to fundamentally change how they work. This is where your process improvement experience becomes crucial. You know how to run kaizen events, how to get stakeholder buy-in, how to measure and communicate success.



Start with a proof of value, not a proof of concept. Pick a process where you can demonstrate measurable improvement within 90 days. Document everything—not just for compliance, but to build your playbook. What worked? What didn't? What would you do differently?



We've found the most successful implementations follow a specific pattern. Week one to four: process mapping and data assessment. Week five to eight: model development and testing. Week nine to twelve: controlled pilot with heavy monitoring. Week thirteen to sixteen: gradual rollout with continuous optimization.




The data assessment phase is critical and often underestimated. You need to understand not just what data you have, but its quality, consistency, and governance. In banking, data lineage is crucial. Where did this data come from? Who owns it? What regulations apply? We use a data readiness scorecard that evaluates completeness, accuracy, consistency, timeliness, and compliance.




One pattern we've seen repeatedly—teams assume they need perfect data to start. They don't. What they need is good enough data with a clear improvement path. We implemented an AI solution for payment exception handling that started with 70% data quality. But because we built in feedback loops, the system actually improved data quality over time by flagging inconsistencies for correction.



Now, measuring success requires rethinking traditional metrics. Yes, we still track efficiency gains—processing time, volume handled, cost per transaction. But we also measure risk reduction, compliance improvements, and employee satisfaction. That payment exception system? It reduced processing time by 50%, but more importantly, it caught 15% more potential fraud cases and improved our audit scores.



The cultural transformation aspect can't be ignored. We're not replacing people—we're augmenting them. Our risk analysts aren't spending time on data entry anymore. They're investigating complex patterns, improving models, and adding their domain expertise where it matters most. This narrative is crucial for adoption.




We run "AI literacy" sessions that aren't about teaching everyone to code. They're about helping teams understand what AI can and can't do, how to work with AI systems, and how to identify opportunities in their own processes. We've trained over 500 staff this year, from risk analysts to relationship managers.




Looking at the competitive landscape, CBA's AI Factory has shown what's possible with committed investment. They're processing millions of transactions daily through AI systems. But you don't need their scale to start. Westpac's productivity gains came from targeted implementations—customer service automation, document processing, fraud detection. Each started small and scaled based on proven value.



The regulatory environment is evolving but becoming clearer. APRA's CPS 230 operational risk requirements actually provide a helpful framework. They're not saying don't use AI—they're saying use it responsibly with appropriate controls. Build those controls into your process design from day one, and compliance becomes a competitive advantage, not a burden.



Here's my challenge to you. Look at your highest-volume, most manual processes. Map them using your existing process improvement tools. Then ask: where could AI eliminate waste? Not replace people, but eliminate the non-value-adding activities that frustrate your teams and slow down your customers.



Start small. Pick one process, build one solution, prove one success. But build it on a foundation that can scale—robust MLOps, clear governance, measurable outcomes. The banks that win in the next decade won't be the ones with the most AI projects. They'll be the ones who've successfully woven AI into the fabric of how they operate, improve, and serve customers.



The opportunity is massive, but it requires a different mindset. Stop thinking about AI as a technology project. Start thinking about it as the next evolution of process improvement. You already have the skills—process mapping, data analysis, change management. Now it's time to augment them with AI and transform how banking works.</description></item><item><title>005 Data Governance And Infrastructure Strategy</title><guid>005_data_governance_and_infrastructure_strategy</guid><pubDate>Sun, 15 Jun 2025 03:01:32 +1000</pubDate><enclosure url="https://github.com/surly-16/js-audio-feed/raw/refs/heads/main/AI%20Foundations%20and%20Implementation/media/005_data_governance_and_infrastructure_strategy.mp3" length="5632173" type="audio/mpeg" /><description>Narrated episode: 005 Data Governance And Infrastructure Strategy</description></item><item><title>001 Ai Applications Across Banking Risk Functions</title><guid>001_ai_applications_across_banking_risk_functions</guid><pubDate>Sun, 15 Jun 2025 02:28:13 +1000</pubDate><enclosure url="https://github.com/surly-16/js-audio-feed/raw/refs/heads/main/AI%20Foundations%20and%20Implementation/media/001_ai_applications_across_banking_risk_functions.mp3" length="6342573" type="audio/mpeg" /><description>Narrated episode: 001 Ai Applications Across Banking Risk Functions</description></item><item><title>003 Mlops For Banking Environments</title><guid>003_mlops_for_banking_environments</guid><pubDate>Sun, 15 Jun 2025 02:28:13 +1000</pubDate><enclosure url="https://github.com/surly-16/js-audio-feed/raw/refs/heads/main/AI%20Foundations%20and%20Implementation/media/003_mlops_for_banking_environments.mp3" length="5836269" type="audio/mpeg" /><description>Narrated episode: 003 Mlops For Banking Environments</description></item><item><title>002 From Rules To Learning Rpa Vs Ai Automation</title><guid>002_from_rules_to_learning_rpa_vs_ai_automation</guid><pubDate>Sun, 15 Jun 2025 02:27:32 +1000</pubDate><enclosure url="https://github.com/surly-16/js-audio-feed/raw/refs/heads/main/AI%20Foundations%20and%20Implementation/media/002_from_rules_to_learning_rpa_vs_ai_automation.mp3" length="4930029" type="audio/mpeg" /><description>Narrated episode: 002 From Rules To Learning Rpa Vs Ai Automation</description></item><item><title>004 Ai Explainability And Model Monitoring</title><guid>004_ai_explainability_and_model_monitoring</guid><pubDate>Sun, 15 Jun 2025 02:27:12 +1000</pubDate><enclosure url="https://github.com/surly-16/js-audio-feed/raw/refs/heads/main/AI%20Foundations%20and%20Implementation/media/004_ai_explainability_and_model_monitoring.mp3" length="4250733" type="audio/mpeg" /><description>Narrated episode: 004 Ai Explainability And Model Monitoring</description></item></channel></rss>