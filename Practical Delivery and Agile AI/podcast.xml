<?xml version='1.0' encoding='utf-8'?>
<rss xmlns:itunes="http://www.itunes.com/dtds/podcast-1.0.dtd" version="2.0"><channel><title>Practical Delivery and Agile AI Feed</title><link>https://surly-16.github.io/js-audio-feed/Practical%20Delivery%20and%20Agile%20AI/</link><description>Narrated episodes on Practical Delivery and Agile AI</description><language>en-au</language><itunes:explicit>no</itunes:explicit><itunes:image href="https://raw.githubusercontent.com/surly-16/js-audio-feed/refs/heads/main/Practical%20Delivery%20and%20Agile%20AI/Cover.png" /><image><url>https://raw.githubusercontent.com/surly-16/js-audio-feed/refs/heads/main/Practical%20Delivery%20and%20Agile%20AI/Cover.png</url><title>Practical Delivery and Agile AI Feed</title><link>https://surly-16.github.io/js-audio-feed/Practical%20Delivery%20and%20Agile%20AI/</link></image><item><title>009 Stakeholder Updates For Experimental Ai Programs</title><guid>009_stakeholder_updates_for_experimental_ai_programs</guid><pubDate>Sun, 15 Jun 2025 04:07:24 +1000</pubDate><enclosure url="https://github.com/surly-16/js-audio-feed/raw/refs/heads/main/Practical%20Delivery%20and%20Agile%20AI/media/009_stakeholder_updates_for_experimental_ai_programs.mp3" length="4774317" type="audio/mpeg" /><description>Narrated episode: 009 Stakeholder Updates For Experimental Ai Programs

Right now, across every major bank in Australia, experimental AI programs are hitting a critical inflection point. The pilots that started eighteen months ago are either scaling into production or getting quietly shelved. And the difference between success and failure? It's not the technology. It's how we communicate progress to stakeholders who control budgets, compliance approvals, and ultimately, our ability to deliver value at scale.

I've spent the last quarter reviewing communication patterns across our AI initiatives, and there's a clear pattern emerging. The teams that secure ongoing funding aren't necessarily building the most sophisticated models. They're the ones who've mastered the art of translating experimental results into business narratives that resonate with risk committees, regulatory bodies, and executive leadership.



Let me share what's actually working. When CBA's AI Factory presents their quarterly updates, they don't lead with model accuracy metrics or technical architecture diagrams. They start with operational outcomes. Last month, their fraud detection pilot showed a forty-three percent reduction in false positives. But here's how they communicated it: "Every week, our relationship managers spend sixteen hours less on manual reviews, allowing them to focus on genuine customer concerns." That's a stakeholder update that lands.

The challenge we face is unique to regulated environments. Unlike tech companies where you can iterate fast and break things, we need to demonstrate control, auditability, and compliance at every stage. APRA's CPS 230 requirements mean every AI experiment needs clear accountability frameworks. ASIC Report 798 on AI governance expects us to explain not just what our models do, but how we ensure they remain fair, transparent, and aligned with customer outcomes.



So how do we structure these updates effectively? I've developed a framework based on lean communication principles, adapted specifically for AI programs in banking contexts. First principle: lead with risk reduction, not just efficiency gains. When Westpac reported on their document processing AI last quarter, they highlighted that error rates dropped from one in two hundred to one in eight thousand. That's not just faster processing; that's reduced operational risk.

Second principle: make the invisible visible. Machine learning models are black boxes to most stakeholders. Your job is to create windows into that box without overwhelming them with technical details. One team I work with uses a simple traffic light system. Green means the model is performing within expected parameters. Amber indicates drift that requires investigation. Red triggers human intervention. During stakeholder updates, they show this dashboard live, demonstrating real-time governance.



Here's where most experimental programs fail in their communication: they treat every stakeholder the same. Your risk committee needs different information than your technology steering group. Risk wants to know about model governance, bias testing, and fallback procedures. Technology leadership cares about scalability, integration points, and technical debt. Executive sponsors need to see strategic alignment and competitive advantage.


Let me give you a concrete example. We recently presented an AI pilot for credit assessment optimization. For the risk committee, we focused on how the model's decision boundaries aligned with existing credit policies, showing side-by-side comparisons of model recommendations versus human decisions over six months. We demonstrated that the AI was actually more conservative than human assessors in edge cases, reducing potential write-offs.


For the same pilot, our technology update emphasized the modular architecture that allows us to swap different models without disrupting downstream systems. We showed how the MLOps pipeline automatically retrains models when data drift exceeds thresholds, maintaining performance without manual intervention.



The executive presentation? Completely different focus. We led with market positioning: "While competitors take six days for complex credit decisions, our AI-assisted process delivers outcomes in four hours, without compromising risk standards." We connected this to strategic priorities around customer experience and operational excellence.

Now, let's talk about handling skepticism, because it's guaranteed in any experimental AI program. Traditional automation teams who've spent years perfecting RPA workflows often view AI as unnecessarily complex. They're not wrong to be cautious. I've seen too many teams jump straight from Excel macros to neural networks, skipping the crucial middle ground of statistical models and decision trees.


The key is to position AI as an evolution, not a revolution.

Show how machine learning extends capabilities beyond rule-based automation. Rules handle the predictable eighty percent. AI tackles the complex twenty percent that currently requires human judgment.



One powerful technique I've borrowed from lean six sigma is the "before and after" process map. Document the current state with all its manual touchpoints, exception handling, and rework loops. Then show the future state with AI components highlighted. But here's the crucial part: explicitly mark which human controls remain. Stakeholders need to see that AI augments human decision-making rather than replacing it entirely.

Communication frequency matters too. Monthly updates are too sparse for experimental programs; quarterly is too long to maintain momentum. I've found that fortnightly touchpoints work best, alternating between detailed progress reports and brief status updates. Use a consistent format. Stakeholders should know exactly where to find the metrics they care about.


Here's my template: Current sprint objectives and progress. Key metrics with trend lines, not just point-in-time snapshots. Risks and mitigation strategies, updated based on latest findings. Upcoming milestones with clear success criteria. Resource requirements or blockers that need escalation.




Let's address the elephant in the room: failed experiments. In traditional IT projects, failure is something to minimize and hide. In AI experimentation, failure is data. The teams that communicate failures effectively actually build more stakeholder trust than those who only report successes.

Last quarter, one of our natural language processing experiments failed to meet accuracy targets for customer complaint categorization. Instead of burying this result, the team presented it as a learning opportunity. They showed that the failure revealed gaps in our training data, specifically around emerging complaint types related to buy-now-pay-later products. This insight led to a broader data quality initiative that's now improving multiple AI programs.



Stakeholder engagement goes beyond formal updates. Create opportunities for hands-on interaction with your AI systems. I run monthly "AI showcase" sessions where stakeholders can test prototypes, ask questions, and provide feedback in a low-pressure environment. These sessions do more for building trust and understanding than any PowerPoint deck.

One particularly effective approach: pair stakeholders with data scientists for "ride-along" sessions. Let them observe model training, feature engineering, and validation processes. Demystifying the technical work helps stakeholders become advocates rather than skeptics.


Remember, every stakeholder update is also a change management opportunity.

You're not just reporting progress; you're building the organizational muscle memory for AI adoption at scale.



Now, let's talk about regulatory communication, because this is where many experimental programs stumble. APRA and ASIC don't expect perfection, but they do expect transparency and control. When preparing updates for regulatory stakeholders, focus on governance processes rather than technical details.

Document your model risk management framework. Show how you identify, assess, and mitigate AI-specific risks. Demonstrate your validation processes, including how you test for bias and ensure fairness across different customer segments. Most importantly, explain your human oversight mechanisms and escalation procedures.

I've found that regulators respond well to phased implementation approaches. Instead of proposing a big-bang AI deployment, show how you're gradually expanding from low-risk use cases to more critical applications, with validation gates at each stage.




Here's a practical tip for technical teams struggling with stakeholder communication: partner with your risk and compliance colleagues early. They speak the language of governance and control that resonates with senior stakeholders. A joint presentation from technology and risk carries far more weight than either alone.


As you prepare your next stakeholder update, ask yourself three questions. First, what decision do I need from this audience? Second, what concerns might prevent them from making that decision? Third, what evidence directly addresses those concerns?

Too many updates fail because they're information dumps rather than decision-enabling documents. Every slide, every metric, every example should drive toward the specific outcome you need, whether that's continued funding, expanded scope, or regulatory approval.



Let me leave you with this thought. The banks that will lead in AI adoption aren't necessarily those with the best technology or the largest budgets. They're the ones that build strong feedback loops between experimental teams and business stakeholders. They create shared ownership of AI outcomes, where success belongs to the entire organization, not just the data science team.

Your experimental AI program is only as strong as the coalition supporting it. Every stakeholder update is an opportunity to strengthen that coalition, building the trust and understanding that enables true transformation. The technical challenges of AI are significant, but they're solvable. The organizational challenges require consistent, thoughtful communication that bridges the gap between possibility and practice.

In our regulated environment, with all its constraints and requirements, this bridge-building isn't optional. It's the difference between AI experiments that remain perpetual pilots and those that deliver real value to customers and shareholders alike. Make every update count.</description></item><item><title>006 Quarterly Epic Planning For Ai Innovation</title><guid>006_quarterly_epic_planning_for_ai_innovation</guid><pubDate>Sun, 15 Jun 2025 04:06:08 +1000</pubDate><enclosure url="https://github.com/surly-16/js-audio-feed/raw/refs/heads/main/Practical%20Delivery%20and%20Agile%20AI/media/006_quarterly_epic_planning_for_ai_innovation.mp3" length="5077101" type="audio/mpeg" /><description>Narrated episode: 006 Quarterly Epic Planning For Ai Innovation</description></item><item><title>008 Measuring Success In Early Stage Ai Squads</title><guid>008_measuring_success_in_early_stage_ai_squads</guid><pubDate>Sun, 15 Jun 2025 04:06:07 +1000</pubDate><enclosure url="https://github.com/surly-16/js-audio-feed/raw/refs/heads/main/Practical%20Delivery%20and%20Agile%20AI/media/008_measuring_success_in_early_stage_ai_squads.mp3" length="1011693" type="audio/mpeg" /><description>Narrated episode: 008 Measuring Success In Early Stage Ai Squads</description></item><item><title>007 Building Mvp Culture In Risk Tech Teams</title><guid>007_building_mvp_culture_in_risk_tech_teams</guid><pubDate>Sun, 15 Jun 2025 04:05:53 +1000</pubDate><enclosure url="https://github.com/surly-16/js-audio-feed/raw/refs/heads/main/Practical%20Delivery%20and%20Agile%20AI/media/007_building_mvp_culture_in_risk_tech_teams.mp3" length="4166061" type="audio/mpeg" /><description>Narrated episode: 007 Building Mvp Culture In Risk Tech Teams</description></item><item><title>002 From Prototype To Production Ai Pilot Pathways</title><guid>002_from_prototype_to_production_ai_pilot_pathways</guid><pubDate>Sun, 15 Jun 2025 04:05:07 +1000</pubDate><enclosure url="https://github.com/surly-16/js-audio-feed/raw/refs/heads/main/Practical%20Delivery%20and%20Agile%20AI/media/002_from_prototype_to_production_ai_pilot_pathways.mp3" length="6890157" type="audio/mpeg" /><description>Narrated episode: 002 From Prototype To Production Ai Pilot Pathways</description></item><item><title>005 Confluence Documentation For Ai Projects</title><guid>005_confluence_documentation_for_ai_projects</guid><pubDate>Sun, 15 Jun 2025 04:04:59 +1000</pubDate><enclosure url="https://github.com/surly-16/js-audio-feed/raw/refs/heads/main/Practical%20Delivery%20and%20Agile%20AI/media/005_confluence_documentation_for_ai_projects.mp3" length="3947949" type="audio/mpeg" /><description>Narrated episode: 005 Confluence Documentation For Ai Projects</description></item><item><title>004 Integrating Ai Initiatives With Risk System Workflows</title><guid>004_integrating_ai_initiatives_with_risk_system_workflows</guid><pubDate>Sun, 15 Jun 2025 04:03:41 +1000</pubDate><enclosure url="https://github.com/surly-16/js-audio-feed/raw/refs/heads/main/Practical%20Delivery%20and%20Agile%20AI/media/004_integrating_ai_initiatives_with_risk_system_workflows.mp3" length="909741" type="audio/mpeg" /><description>Narrated episode: 004 Integrating Ai Initiatives With Risk System Workflows</description></item></channel></rss>