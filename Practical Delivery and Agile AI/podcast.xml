<?xml version='1.0' encoding='utf-8'?>
<rss xmlns:itunes="http://www.itunes.com/dtds/podcast-1.0.dtd" version="2.0"><channel><title>Practical Delivery and Agile AI Feed</title><link>https://surly-16.github.io/js-audio-feed/Practical%20Delivery%20and%20Agile%20AI/</link><description>Narrated episodes on Practical Delivery and Agile AI</description><language>en-au</language><itunes:explicit>no</itunes:explicit><itunes:image href="https://github.com/surly-16/js-audio-feed/blob/main/Practical%20Delivery%20and%20Agile%20AI/cover.png?raw=true" /><image><url>https://github.com/surly-16/js-audio-feed/blob/main/Practical%20Delivery%20and%20Agile%20AI/cover.png?raw=true</url><title>Practical Delivery and Agile AI Feed</title><link>https://surly-16.github.io/js-audio-feed/Practical%20Delivery%20and%20Agile%20AI/</link></image><item><title>009 Stakeholder Updates For Experimental Ai Programs</title><guid>009_stakeholder_updates_for_experimental_ai_programs</guid><pubDate>Sun, 15 Jun 2025 03:33:59 +1000</pubDate><enclosure url="https://github.com/surly-16/js-audio-feed/raw/refs/heads/main/Practical%20Delivery%20and%20Agile%20AI/media/009_stakeholder_updates_for_experimental_ai_programs.mp3" length="5770413" type="audio/mpeg" /><description>Narrated episode: 009 Stakeholder Updates For Experimental Ai Programs

Right now, across every major bank in Australia, experimental AI programs are hitting a critical inflection point. The pilots that started eighteen months ago are either scaling into production or getting quietly shelved. And the difference between success and failure? It's not the technology. It's how we communicate progress to stakeholders who control budgets, compliance approvals, and ultimately, our ability to transform how banking operations actually work.

I've been leading AI initiatives here for the past two years, and I've watched brilliant technical solutions die because we couldn't translate their value into language that resonates with risk committees, board members, and frontline managers. Today, I'm sharing the communication framework that's helped us move from isolated experiments to enterprise-wide adoption.



Let's start with the fundamental shift in how we frame these updates. Traditional project reporting focuses on milestones completed and features delivered. But experimental AI programs don't follow linear paths. They're iterative, exploratory, and often pivot based on what we learn. So instead of reporting on completion percentages, we report on validated learnings and risk reduction metrics.

Here's a concrete example. Our credit assessment automation pilot started with the goal of reducing processing time. Classic efficiency play. But three months in, we discovered the AI was identifying documentation inconsistencies that human reviewers missed in twenty percent of applications. That's not efficiency anymore—that's risk mitigation. When we pivoted our stakeholder updates to emphasize this compliance improvement, suddenly we had the Chief Risk Officer advocating for expansion rather than questioning the investment.



The structure I use for every stakeholder update follows what I call the PROVE framework. P for Problem validation, R for Results achieved, O for Operational integration, V for Value delivered, and E for Evolution pathway. Let me break this down with real examples from our current programs.

Problem validation always comes first because stakeholders need reminding why we started. Not the generic "improve efficiency" nonsense, but the specific operational pain point. For our trade finance team, it was the forty-three percent error rate in letter of credit reviews causing AUSTRAC reporting delays. Specific, measurable, tied to compliance risk. Every update starts by reinforcing this problem still exists and still matters.

Results achieved focuses on evidence, not promises. We don't say "the model achieved ninety-two percent accuracy." We say "in parallel testing over two thousand transactions, the AI flagged seventeen high-risk patterns that passed human review, preventing potential breaches worth four point two million in regulatory penalties." See the difference? One's a metric, the other's a business outcome.




Operational integration is where most AI pilots fail, and it's where our stakeholder communication becomes critical. We map exactly how the AI fits into existing workflows, who needs training, which systems need integration, and most importantly, how we maintain human oversight for APRA compliance. 

For our customer complaint classification system, we created visual workflow diagrams showing how the AI pre-processes complaints, routes them to appropriate teams, but always includes human validation checkpoints. We also highlight how existing KPIs and SLAs remain intact—the AI enhances rather than replaces current accountability structures.


Value delivered translates technical achievements into CFO-friendly language. But here's the key: we report value across three dimensions. Efficiency gains are table stakes—yes, we reduced processing time by sixty percent. Risk reduction is more compelling—we identified two hundred thousand dollars in duplicate payments that slipped through manual controls. But strategic enablement is what gets executive attention—we can now offer same-day trade finance approvals, matching Commbank's digital capabilities.

Evolution pathway addresses the "what's next" question before it's asked. We present three scenarios: conservative expansion within the same domain, moderate expansion to adjacent processes, and transformational expansion across business lines. Each scenario includes investment requirements, risk assessments, and importantly, dependencies on other initiatives like data platform upgrades or policy changes.



Now, let's talk about tailoring these updates for different stakeholder groups because one size definitely doesn't fit all. Board members care about strategic alignment and risk governance. They want to know how AI initiatives support the bank's digital transformation strategy and what controls prevent algorithmic bias or regulatory breaches. I frame updates around competitive positioning—how CBA's AI Factory processes a million home loan applications annually while maintaining compliance, and how our initiatives close that capability gap.

Risk and compliance stakeholders need deep dives into control mechanisms. Every update includes our three-lines-of-defense model for AI governance. First line: embedded quality checks in the AI pipeline. Second line: independent model validation by our risk team. Third line: periodic audits including explainability assessments. We also map every AI capability against CPS 230 operational risk requirements and ASIC's Report 798 guidelines on AI governance.



Frontline managers and team leaders need practical implementation details. They're worried about job displacement, skill gaps, and daily workflow disruptions. Our updates emphasize augmentation over automation. We show how the mortgage processing AI handles document extraction and validation—the tedious stuff—while processors focus on customer relationships and complex case assessment. We include training timelines, support resources, and crucially, success stories from early adopters within their own teams.

Technical teams want architectural decisions and integration challenges. But even here, we frame updates around business value. Yes, we chose Azure ML over SageMaker, but the story is about leveraging existing Azure DevOps pipelines to accelerate deployment, not about technical preferences. We discuss how our feature store enables model reusability across teams, reducing development time for new use cases by seventy percent.




One critical element often missed in stakeholder communication is addressing the failures and pivots transparently. Every experimental program has them. Our invoice processing bot achieved ninety-five percent accuracy on standard invoices but completely failed on handwritten annotations. Instead of hiding this, we turned it into a learning story about edge case identification and the importance of comprehensive training data.

We also share when we kill initiatives. Our chatbot for internal IT support seemed promising until we realized seventy percent of queries required system access the bot couldn't have for security reasons. Sharing this saved other teams from similar dead ends and demonstrated fiscal responsibility—we're not pursuing AI for AI's sake.




The communication cadence matters as much as content. We run monthly showcase sessions where stakeholders can see live demonstrations, not just PowerPoint slides. Watching an AI process a complex trade finance document in real-time, flag risks, and generate compliance reports does more for buy-in than any metric dashboard.

We also maintain what I call an "AI Impact Tracker"—a simple dashboard showing cumulative benefits across all programs. Processing time saved, errors prevented, compliance issues caught, customer satisfaction improvements. Updated weekly, accessible to all stakeholders. It transforms individual pilot successes into an enterprise transformation narrative.

For regulated environments like banking, we've learned to lead with compliance wins. When our transaction monitoring AI identified a money laundering pattern that traditional rules missed, that became our lead story for three months. Not because it was our biggest technical achievement, but because it demonstrated AI's value in the space executives care most about—regulatory risk.



Here's something counterintuitive: we celebrate small wins more than big ones. When our document classification AI correctly routed its first thousand documents with zero errors, we made more noise about that than when it hit a million. Why? Because stakeholders need confidence in reliability over scale. They need to trust the foundation before they'll support the skyscraper.

We also use what I call "translation bridges"—analogies that connect AI concepts to familiar processes. Machine learning model training becomes "teaching the system like training a new employee." Feature engineering becomes "choosing the right data points like selecting KPIs for a balanced scorecard." Model drift becomes "process degradation requiring continuous improvement." These bridges help non-technical stakeholders grasp complex concepts without dumbing down the substance.



The most powerful communication tool we've developed is our "AI Readiness Scorecard" for each business unit. It assesses data quality, process standardization, change readiness, and technical infrastructure. But here's the key—we let business units score themselves, then work with them to improve. This transforms AI from something imposed by innovation teams to something business units actively prepare for and request.


We've also learned to communicate differently about different types of AI. Predictive models for credit risk get framed around accuracy and backtesting. Natural language processing for complaint analysis emphasizes comprehensiveness and consistency. Computer vision for document processing focuses on speed and error reduction. Each technology has its natural value proposition—force-fitting them into generic ROI calculations misses the point.




Looking at successful programs across the industry, there are clear patterns. Westpac's customer service AI succeeded because they communicated it as empowering staff to handle complex queries by automating routine ones. ANZ's fraud detection ML gained traction by emphasizing customer protection over cost savings. NAB's process automation initiatives frame everything around "giving time back to humans for human work."

The failures are equally instructive. Every bank that tried to implement AI without clear business sponsorship failed. Every program that couldn't articulate value beyond efficiency metrics stalled. Every initiative that surprised stakeholders with unexpected risks or integration challenges got shut down. Communication isn't just about selling the vision—it's about building trust through transparency.



As we scale from pilots to production, stakeholder communication evolves too. Early stage focuses on potential and learning. Growth stage emphasizes reliability and integration. Maturity stage shifts to optimization and expansion. But throughout, we maintain consistent themes: human-centric augmentation, robust risk management, and measurable business value.

The banks winning the AI race aren't necessarily those with the best technology. They're the ones who've mastered the art of bringing stakeholders along the journey. They've turned skeptics into champions by speaking their language, addressing their concerns, and delivering value they care about.



Here's my challenge for you: audit your current stakeholder communications. Are you reporting on activities or outcomes? Features or value? Technical achievements or business impact? Then pick one experimental program and reframe its next update using the PROVE framework. Focus on validated learnings over completion metrics. Emphasize risk reduction alongside efficiency. Show how it fits into existing workflows, not how it disrupts them.

Remember, in regulated industries like banking, trust is our license to operate. Every stakeholder update either builds or erodes that trust. Make sure yours builds it, one validated learning at a time. Because ultimately, the best AI strategy in the world means nothing if we can't bring our stakeholders along for the transformation.</description></item><item><title>006 Quarterly Epic Planning For Ai Innovation</title><guid>006_quarterly_epic_planning_for_ai_innovation</guid><pubDate>Sun, 15 Jun 2025 03:33:02 +1000</pubDate><enclosure url="https://github.com/surly-16/js-audio-feed/raw/refs/heads/main/Practical%20Delivery%20and%20Agile%20AI/media/006_quarterly_epic_planning_for_ai_innovation.mp3" length="5132589" type="audio/mpeg" /><description>Narrated episode: 006 Quarterly Epic Planning For Ai Innovation</description></item><item><title>003 Managing Ai Sprints And User Stories In Jira</title><guid>003_managing_ai_sprints_and_user_stories_in_jira</guid><pubDate>Sun, 15 Jun 2025 03:31:49 +1000</pubDate><enclosure url="https://github.com/surly-16/js-audio-feed/raw/refs/heads/main/Practical%20Delivery%20and%20Agile%20AI/media/003_managing_ai_sprints_and_user_stories_in_jira.mp3" length="4085229" type="audio/mpeg" /><description>Narrated episode: 003 Managing Ai Sprints And User Stories In Jira</description></item><item><title>008 Measuring Success In Early Stage Ai Squads</title><guid>008_measuring_success_in_early_stage_ai_squads</guid><pubDate>Sun, 15 Jun 2025 03:13:16 +1000</pubDate><enclosure url="https://github.com/surly-16/js-audio-feed/raw/refs/heads/main/Practical%20Delivery%20and%20Agile%20AI/media/008_measuring_success_in_early_stage_ai_squads.mp3" length="6828525" type="audio/mpeg" /><description>Narrated episode: 008 Measuring Success In Early Stage Ai Squads</description></item><item><title>007 Building Mvp Culture In Risk Tech Teams</title><guid>007_building_mvp_culture_in_risk_tech_teams</guid><pubDate>Sun, 15 Jun 2025 03:11:28 +1000</pubDate><enclosure url="https://github.com/surly-16/js-audio-feed/raw/refs/heads/main/Practical%20Delivery%20and%20Agile%20AI/media/007_building_mvp_culture_in_risk_tech_teams.mp3" length="5202093" type="audio/mpeg" /><description>Narrated episode: 007 Building Mvp Culture In Risk Tech Teams</description></item><item><title>005 Confluence Documentation For Ai Projects</title><guid>005_confluence_documentation_for_ai_projects</guid><pubDate>Sun, 15 Jun 2025 03:10:35 +1000</pubDate><enclosure url="https://github.com/surly-16/js-audio-feed/raw/refs/heads/main/Practical%20Delivery%20and%20Agile%20AI/media/005_confluence_documentation_for_ai_projects.mp3" length="4729773" type="audio/mpeg" /><description>Narrated episode: 005 Confluence Documentation For Ai Projects</description></item><item><title>002 From Prototype To Production Ai Pilot Pathways</title><guid>002_from_prototype_to_production_ai_pilot_pathways</guid><pubDate>Sun, 15 Jun 2025 03:10:03 +1000</pubDate><enclosure url="https://github.com/surly-16/js-audio-feed/raw/refs/heads/main/Practical%20Delivery%20and%20Agile%20AI/media/002_from_prototype_to_production_ai_pilot_pathways.mp3" length="6759021" type="audio/mpeg" /><description>Narrated episode: 002 From Prototype To Production Ai Pilot Pathways</description></item><item><title>004 Integrating Ai Initiatives With Risk System Workflows</title><guid>004_integrating_ai_initiatives_with_risk_system_workflows</guid><pubDate>Sun, 15 Jun 2025 03:10:01 +1000</pubDate><enclosure url="https://github.com/surly-16/js-audio-feed/raw/refs/heads/main/Practical%20Delivery%20and%20Agile%20AI/media/004_integrating_ai_initiatives_with_risk_system_workflows.mp3" length="5017773" type="audio/mpeg" /><description>Narrated episode: 004 Integrating Ai Initiatives With Risk System Workflows</description></item><item><title>001 Running Ai Experiments In Risk Management Squads</title><guid>001_running_ai_experiments_in_risk_management_squads</guid><pubDate>Sun, 15 Jun 2025 03:08:48 +1000</pubDate><enclosure url="https://github.com/surly-16/js-audio-feed/raw/refs/heads/main/Practical%20Delivery%20and%20Agile%20AI/media/001_running_ai_experiments_in_risk_management_squads.mp3" length="5455725" type="audio/mpeg" /><description>Narrated episode: 001 Running Ai Experiments In Risk Management Squads</description></item></channel></rss>